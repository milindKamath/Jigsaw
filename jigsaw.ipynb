{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.preprocessing.text import one_hot\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sep = os.path.sep\ndataDirec = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification' + sep\nfilt = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def readDataFrame():\n    dfTrain = pd.read_csv(dataDirec + 'jigsaw-toxic-comment-train.csv')\n    dfBias = pd.read_csv(dataDirec + 'jigsaw-unintended-bias-train.csv')\n    dfValid = pd.read_csv(dataDirec + 'validation.csv')\n    dfTest = pd.read_csv(dataDirec + 'test.csv')\n    return dfTrain, dfBias, dfValid, dfTest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, bias, valid, test = readDataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getData(train, bias, valid, test):\n    \n    trainData = np.array(train['comment_text'])\n    \n    biasData = np.array(bias['comment_text'])\n    \n    trainLabel = np.array(train['toxic'])\n    biasLabel = np.round(np.array(bias['toxic']))\n    \n    testData = np.array(test['content'])\n    \n    validData = np.array(valid['comment_text'])\n    \n    validLabel = np.array(valid['toxic'])\n    \n    Xtrain = np.r_[trainData, biasData]\n    Xlabel = np.r_[trainLabel, biasLabel]\n    \n    Xtrain, Xlabel = shuffle(Xtrain, Xlabel, random_state=0)    \n    \n    validData, validLabel = shuffle(validData, validLabel, random_state=0)\n    \n    return Xtrain[:1000000], Xlabel[:1000000], validData, validLabel, testData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain, Xlabels, validData, validLabel, testData = getData(train, bias, valid, test)\ndel train, bias, valid, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preProcess(Xtrain, validData, test):\n    for i, sent in enumerate(Xtrain):\n        if i % 100000 == 0:\n            print(i, end='\\r')\n        Xtrain[i] = one_hot(sent, 400, filters=filt, lower=True, split=' ')\n    Xtrain = sequence.pad_sequences(Xtrain, maxlen=400, padding='post')\n    print(\"Done\")\n    \n    for i, sent in enumerate(validData):\n        if i % 1000 == 0:\n            print(i, end='\\r')\n        validData[i] = one_hot(sent, 400, filters=filt, lower=True, split=' ')\n    validData = sequence.pad_sequences(validData, maxlen=400, padding='post')\n    print(\"Done\")\n\n    for i, sent in enumerate(test):\n        if i % 10000 == 0:\n            print(i, end='\\r')\n        test[i] = one_hot(sent, 400, filters=filt, lower=True, split=' ')\n    test = sequence.pad_sequences(test, maxlen=400, padding='post')\n    print(\"Done\")\n\n    return Xtrain, validData, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain, validData, testData = preProcess(Xtrain, validData, testData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = tf.keras.utils.normalize(Xtrain, axis=-1, order=2)\nvalidData = tf.keras.utils.normalize(validData, axis=-1, order=2)\ntestData = tf.keras.utils.normalize(testData, axis=-1, order=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(train, labels, batch_size):\n    while True:\n        ind = np.random.choice(np.where(labels == 0)[0], batch_size//2)\n        ind1 = np.random.choice(np.where(labels == 1)[0], batch_size//2)\n        train = np.r_[train[ind], train[ind1]]\n        labels = np.r_[labels[ind], labels[ind1]]\n        yield train, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createModel(Xtrain, Xlabels):\n    max_words = 400\n    lstmSize = 120\n    epochs = 5\n    batch_size = 300\n    validation_split = int(0.03 * Xtrain.shape[0])\n    callBack = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n    metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    class_weights = class_weight.compute_class_weight('balanced', np.unique(Xlabels), Xlabels)\n    \n    validData = Xtrain[:validation_split]\n    validLabel = Xlabels[:validation_split]\n    \n    model = Sequential()\n    model.add(Embedding(max_words, lstmSize))\n    model.add(LSTM(lstmSize, dropout=0.4, recurrent_dropout=0.5))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4), bias_regularizer=tf.keras.regularizers.l2(1e-4)))\n    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    \n    model.summary()\n        \n    model.fit(generator(Xtrain, Xlabels, batch_size), epochs=epochs, verbose=1, validation_data=(validData, validLabel), steps_per_epoch=500, callbacks=[callBack], shuffle=True)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = createModel(np.r_[Xtrain, validData], np.r_[Xlabels, validLabel])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pseudoLabel = model.predict(testData, batch_size=32, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = createModel(np.r_[Xtrain, validData, testData], np.r_[Xlabels, validLabel, pseudoLabel[:, 0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Label = model.predict(testData, batch_size=32, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'id': np.arange(0, len(testData)), 'toxic': Label[:, 0]}\ndframe = pd.DataFrame(data=data)\ndframe.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}